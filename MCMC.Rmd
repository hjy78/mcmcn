---
title: "马尔可夫链蒙特卡罗（MCMC）方法及其应用"
author: "黄佳谊"
output:
  html_document: 
    toc: yes 
    toc_float:
      collapsed: no
    number_sections: yes
---

```{r, setup, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE)
```

```{r include=FALSE}
library(mcmcn)
```

# 简介

假设现有一个概率分布$f(\cdot)$，目标是对其进行随机抽样，或是求函数关于该概率分布的数学期望。可以采用传统的蒙特卡罗法，如接受-拒绝法、重要性抽样法等。也可以使用**马尔可夫链蒙特卡罗方法**，该方法更适合于随机变量是多元的、密度函数是非标准形式的、随机变量各分量不独立等情况。

**马尔可夫链蒙特卡罗（MCMC）方法**主要是基于Metropolis等人和Hastings提出的蒙特卡罗积分法的一般框架。该方法根据目标密度$f(\cdot)$，通过MCMC方法构造一个具有平稳分布$f(\cdot)$的Markov链，然后运行充分长的时间直到该链（近似）收敛于它的平稳分布。

# MCMC方法需要的定理

为此，需要关于Markov链及蒙特卡罗方法的定义及定理（关于Markov链的一般性介绍参见《随机过程》，Ross）。

**定义1（连续状态Markov链）** 称$X=\{X_0,X_1,\dots,X_t,\dots\}$为连续状态Markov链，若随机变量$X_t(t=0,1,2,\dots)$定义在连续状态空间$S$，转移概率分布由转移核（transition kernel）表示。$\forall x\in S,A\subset S$，转移核$P(x,A)$定义为
$$
P(x,A)=\int_Ap(x,y)dy
$$
其中$p(x,\cdot)$是概率转移函数，满足$p(x,\cdot)\ge0$，$P(x,S)=\int_Sp(x,y)dy=1$，转移核$P(x,A)$表示从$x\to A$的转移概率
$$
P(X_t=A|X_{t-1}=x)=P(x,A)
$$

**定义2（平稳分布）**称连续状态Markov链的状态空间$S$上的概率分布$\pi(x)$是平稳分布，若满足条件
$$
\pi(y)=\int p(x,y)\pi(x)dx,\ \forall y\in S
$$
或等价地
$$
\pi(A)=\int P(x,A)\pi(x)dx,\ \forall A\subset S
$$
对于离散状态的Markov链可用概率矩阵表示为
$$
\pi=\mathbb{P}\pi
$$

**定义3（不可约）** 设有Markov链$X=\{X_0,X_1,\dots,X_t,\dots\}$，状态空间为$S$，对于任意状态$i,j\in S$，如果存在一个时刻$t(t>0)$满足
$$
P(X_t=i|X_0=j)>0
$$
则称此Markov链是不可约的（irreducible），否则称Markov链是可约的（reducible）。

**定义4（非周期）** 设有Markov链$X=\{X_0,X_1,\dots,X_t,\dots\}$，状态空间为$S$，对于任意状态$i\in S$，如果对所有满足$P(X_t=i|X_0=0)>0$的$t$的最大公约数是1，则称此Markov链$S$是非周期的（aperiod），否则为周期的（periodic）。

**定义5（正常返）** 设有Markov链$X=\{X_0,X_1,\dots,X_t,\dots\}$，状态空间为$S$，对于任意状态$i,j\in S$，定义$p_{ij}^t$为时刻0从状态$j$出发，时刻$t$首次转移到状态$i$的概率，即$p_{ij}^t =P(X_t=i,X_s\ne i,s=1,2,\dots,t-1|X_0=j),t=1,2,\dots$。若对所有状态$i,j$都满足$\lim_{t\to\infty} p_{ij}^t>0$，则称Markov链是正常返的（positive recurrent）。

**定理1（平稳分布）** 不可约、非周期且正常返的Markov链，有唯一平稳分布存在。

证明见《随机过程》，Ross

**定理2（遍历定理）** 设有Markov链$X=\{X_0,X_1,\dots,X_t,\dots\}$，状态空间为$S$，若Markov链$X$是不可约、非周期且正常返的，该Markov链唯一平稳分布为$\pi(x)$，设$g(x)$为定义于状态空间$S$上的函数，则
$$
\lim_{t\to\infty}\frac{1}{t}\sum_{k=1}^{t}f(X_k)=\mathrm{E}[f(X)]
$$
定理2的正确性由定理1和强大数律保证。

**定义6（可逆Markov链）** 设有Markov链$X=\{X_0,X_1,\dots,X_t,\dots\}$，状态空间为$S$，转移核为$K(\cdot,\cdot)$，如果有状态分布$\pi(\cdot)$，对于任意状态$x,y\in S$，对任意一个时刻$t$满足
$$
K(y,x)\pi(y)=K(x,y)\pi(x),\ x,y\in S
$$
则称此Markov链$X$为可逆Markov链（reversible Markov chain），上式称为细致平衡方程（detailed balance equation）。

**定理3（细致平衡方程）** 满足细致平衡方程的状态分布$\pi$是该Markov链的平稳分布，即
$$
\pi(y)=\int p(x,y)\pi(x)dx,\ \forall y\in S
$$
证明：对细致平衡方程两边同时对$x$在$S$积分即可。

**定理2**和**定理3**为Metropolis-Hastings算法提供了理论依据。

# Metropolis-Hastings样本生成器

Metropolis-Hastings算法是一类MCMC方法，它包括了Metropolis-Hastings样本生成器、Metropolis样本生成器、随机游动Metropolis样本生成器和独立性样本生成器等样本生成器，其中Metropolis样本生成器、随机游动Metropolis样本生成器、独立性样本生成器是特殊的Metropolis-Hastings样本生成器。

假设多元随机变量$x$，满足$x\in S$，其概率密度函数为$f(x)$，目标是获得概率分布$f(x)$的样本集合。

Metropolis-Hastings算法的主要想法如下：生成一个平稳分布为$f(x)$的Markov链$X=\{X_0,X_1,\dots,X_t,\dots\}$，从一个给定的状态$X_t$生成下一个状态$X_{t+1}$的算法必须详细说明。在所有的MCMC抽样算法中都存在着一个从建议分布$g(\cdot|X_t)$生成的候选点$Y$，如果这个候选点被接受了，那么链条在时刻$t+1$移动到状态$Y$即$X_{t+1}=Y$，否则链条停留在状态$X_t$且$X_{t+1}=X_t$。

将Metropolis样本生成器的步骤概括如下：

假设样本为$d$维向量，产生$n$个样本

1. 对于目标分布$f(x)$，选择一个合适的建议分布$g(\cdot|X_t)$；
2. 选择初值$X_0$,置$k=0$；
3. 重复下列过程有限（$n$）次（如果设置了burn，则重复$n+$burn次）：
    a. 从建议分布$g(\cdot|X_t)$生成候选点$Y$;
    b. 从$\mathrm{U}(0,1)$生成$\mathrm{U}$；
    c. 如果
        $$
        U\le\frac{f(Y)g(X_t|Y)}{f(X_t)g(Y|X_t)}
        $$
        则接受$Y$并令$X_{t+1}=Y$；否则令$X_{t+1}=X_t$，增加$k$；
    d. 增加$t$.
4. 如果设置burn，舍去前burn个样本;
    返回$n\times d$的矩阵，每一行为一个样本。以及拒绝率$\frac{k}{n+\text{burn}}$

**注意：**在步骤3c中候选点$Y$被接受的概率为
$$
\alpha(X_t,Y)=\min\{1,\frac{f(Y)g(X_t|Y)}{f(X_t)g(Y|X_t)}\}
$$
所以只需要知道忽略标准化常数的目标分布$f$的密度函数，在实际使用中也常常将常数略去以简化计算。

建议分布的选择是非常灵活的，但是由这个选择生成的链条却必须满足某些正则性条件：选择的建议分布必须使得生成的链条收敛到平稳分布$f$，生成的链条还需要具有不可约性、正常返性和非周期性。如果一个建议分布和目标分布具有相同的支撑集，那么它一般都会满足这些正则性条件，若不满足，可以通过观察链条的转移情况来发现以及改进，直到观察到选择的建议分布产生的Markov链能够收敛。

假设建议分布满足正则性条件，Markov链将会收敛到唯一的平稳分布$\pi$，需要寻找建议分布$g(\cdot|X_t)$使得Markov链的平稳分布确实是目标分布$f$。

**定理（Metropolis）** 假设多元随机变量$x$，满足$x\in S$，其概率密度函数为$f(x)$，通过Metropolis-Hastings方法产生的Markov链的平稳分布为$f$

证明：假设$r,s\in S$，不失一般性设$f(s)g(s|r)\ge f(r)g(s|r)$。这样$\alpha(r,s)=1$，$(X_t,X_{t+1})$在$(r,s)$的联合密度为$f(r)g(s|r)$。$(X_t,X_{t+1})$在$(s,r)$的联合密度为
$$
f(s)g(r|s)\alpha(s,r)=f(s)g(r|s)\frac{f(r)g(s|r)}{f(s)g(r|s)}=f(r)g(s|r)
$$
转移核为
$$
K(r,s)=\alpha(r,s)g(s|r)+\mathrm{I}_{\{r=s\}}(1-\int\alpha(r,s)g(s|r)ds)
$$
这样对Metropolis-Hastings链条得到了方程组
$$
\alpha(r,s)f(r)g(s|r)=\alpha(s,r)f(s)g(r|s)
$$
$$
\mathrm{I}_{\{s=r\}}[1-\int\alpha(r,s)g(s|r)dsf(r)]=\mathrm{I}_{\{r=s\}}[1-\int\alpha(s,r)g(r|s)drf(s)]
$$
$f$满足细致平衡方程$K(s,r)f(s)=K(r,s)f(r),\ s,r\in S$，因此由定理3知$f$是Markov链的平稳分布。

根据定理2，当时间趋于无穷时，样本的分布趋近平稳分布，样本的函数均值趋近函数的数学期望。所以，当时间足够长（$t>m$）时，在之后的时间（$m<t<n$）里运行Markov链得到的样本集合就是目标概率分布的抽样结果，得到的函数均值就是要计算的数学期望值：
$$
\mathrm{E}[f(X)]\approx\frac{1}{n-m}\sum_{i=m+1}^nf(X_i)
$$
到时刻m为止的时间称为燃烧（burn）期。

## Metropolis样本生成器

Metropolis-Hastings样本生成器是Metropolis样本生成器的一个推广，在Metropolis样本生成器中建议分布是对称的，即建议分布$g(\cdot,X_t)$满足
$$
g(X|Y)=g(Y|X)
$$
所以Metropolis-Hastings样本生成器算法中的$\alpha(X_t,Y)$中可以约去建议分布$g$，即
$$
\alpha(X_t,Y)=\min\{1,\frac{f(Y)}{f(X_t)}\}
$$

## 随机游动Metropolis样本生成器

随机游动Metropolis样本生成器是一个Metropolis样本生成器的例子，假设候选点$Y$是根据对称建议分布$g(Y|X_t)=g(|X_t-Y|)$生成的，那么在每次迭代中，从$g(\cdot)$中生成了一个随机增量$Z$，$Y$定义为$Y=X_t+Z$。

随机游动Metropolis样本生成器的收敛性对尺度参数的选择非常敏感，当增量的方差非常大时，大多数的候选点都被拒绝了，算法的效率非常低，但若增量的方差过小，候选点几乎全部被接受了，所以随机游动Metropolis样本生成器生成了一个几乎类似真正随机游动的链条，这也是非常低效率的。选择尺度参数的一个方法是检测接受率，它应该在[0.15,0.5]范围内。

## 独立性样本生成器

独立性样本生成器是Metropolis-Hastings样本生成器的另一种特殊情况，独立性样本生成器中的建议分布不依赖于链条先前的值，这样$g(Y|X_t)=g(Y)$，此时
$$
\alpha(X_t,Y)=\min\{1,\frac{f(Y)g(X_t)}{f(X_t)g(Y)}\}
$$
独立性样本生成器很容易实现，并且在建议分布和目标分布相近时效果很好，但是二者不相近时效果很差。

# Metropolis-Hastings算法的R语言实现及例子

针对目标函数的支撑集范围不同，编写了通用函数`mtrp`,`mtrp_exp`,`mtrp_expu`，`mtrp_unif`，均适用于任意给定的目标函数与任意维情形。上述函数可以通过加载R包`mcmcn`直接使用，源代码和实现方法见文末。

之后通过一个例子，发现了`mtrp_exp`对于和指数分布不相近的分布效果很差，为情形2另外编写了函数`mtrp_expu`，该函数使用均匀分布和指数分布的合成做建议分布，使用Metropolis-Hastings样本生成器来生成样本。

## 情形1 `mtrp`

对目标函数的支撑集不做限制，编写了函数`mtrp`，该函数使用正态分布做建议分布，使用随机游动Metropolis样本生成器来产生样本。

### 多元正态分布

本例中，对给定的二维正态分布参数$(\mu,\Sigma)$产生10000个样本，考察其拒绝率、均值、方差等指标，并通过可视化观察Markov链转移过程和样本的分布情况，之后讨论了选取不同的初值（`init`参数），建议函数（正态分布）的标准差（`stepsize`参数），对于拒绝率和收敛性的影响。

给定二维正态分布参数`mu <- c(1,3)
A <- matrix(c(1, 0.1, 0.1, 1), nrow = 2)`
```{r}
# multivariate normal distribution pdf(mu, A)
mu <- c(1,3)
A <- matrix(c(1, 0.1, 0.1, 1), nrow = 2)
A.inv <- solve(A)
f <- function(x) {
  return(as.vector(exp(-0.5 * t(x - mu) %*% A.inv %*% (x - mu))))
}
```

产生10000个样本存储在`mtrp.chain`中
```{r}
# generating random variates
set.seed(1234)
x.norm <- mtrp(f, 10000, c(3, 3), burn = 0)

# exploring the results
summary(x.norm)
plot(x.norm)
par(mfrow = c(1, 2))
plot(x.norm$chain, pch = 20, cex = 0.5, main = "Sample Distribution",
     xlab = "1st variable", ylab = "2nd variable")
qqnorm(x.norm$chain[, 1], main = "QQ plot, 1st variable")
par(mfrow = c(1, 1))
```

可以看到44.46%的候选点被拒绝了，所以这个链条在某种程度上效率很低。样本均值、样本协方差矩阵与理论值较相近。第一个坐标分类的时间图中，有时候样本被拒绝了，对应图中的短横线。从样本分布与目标分布的QQ图可以看出样本分位数和理论分位数近似吻合。

比较不同初值对结果的影响`c(-4, 3), c(1, 3), c(6, 3)`
```{r}
# exploring the results of different initial values
set.seed(1234)
par(mfrow = c(2, 1))
x.norm1 <- mtrp(f, 10000, c(-4, 3), burn = 0)
x.norm2 <- mtrp(f, 10000, c(1, 3), burn = 0)
x.norm3 <- mtrp(f, 10000, c(6, 3), burn = 0)
plot(1:500, x.norm1$chain[1:500, 1], type = "l", col = "red",
     ylab = "1st variable", ylim = c(-4, 6), main = "first 500 iters")
lines(1:500, x.norm2$chain[1:500, 1], col = "green")
lines(1:500, x.norm3$chain[1:500, 1], col = "blue")
points(rep(1, 3), c(-4, 1, 6), col = c("red", "green", "blue"), pch = 20)
plot(9001:9500, x.norm1$chain[9001:9500, 1], type = "l", col = "red",
     ylab = "1st variable", ylim = c(-4, 6), main = "last 500 iters")
lines(9001:9500, x.norm2$chain[9001:9500, 1], col = "green")
lines(9001:9500, x.norm3$chain[9001:9500, 1], col = "blue")
par(mfrow = c(1, 1))
```

上图中红、蓝、绿三种颜色分别表示了给定不同初值产生的Markov链的转移情况，可以看到，本例中Markov链很快到达稳态，不同初值对于Markov链的影响可以通过舍去开始的m个样本来消除。

比较不同建议函数（正态分布）的标准差对结果的影响`stepsize in exp(seq(-2, 1, length.out = 4))`
```{r}
# exploring the results of different stepsizes
set.seed(1234)
par(mfrow = c(2, 1))
for (stepsize in exp(seq(-2, 1, length.out = 4))) {
  x.norm <- mtrp(f, 1000, c(5, 3), stepsize = stepsize, burn = 0)
  plot(
    x.norm$chain[, 1],
    type = "l", ylab = "1st variable",
    main = paste("stepsize", round(stepsize,2), "rejection rate", round(x.norm$alpha,2))
  )
}
par(mfrow = c(1, 1))
```

观察上图可以看到该样本生成器的收敛性对正态分布的标准差（尺度参数）的选择非常敏感，当增量的方差非常大（`stepsize` = 2.72）时，Markov链很快收敛，但大多数的候选点都被拒绝了，算法的效率非常低；但若增量的方差过小（`stepsize` = 0.14），经过很长时间才回到期望附近，候选点几乎全部被接受了，所以随机游动Metropolis样本生成器生成了一个几乎类似真正随机游动的链条，这也是非常低效率的；`stepsize`的合理范围是(0.37, 1)，拒绝率既不会太高，也不会有Markov链难以收敛的情况。

### 混合多元正态分布

混合正态分布是典型的多峰分布，本例中通过将两个正态分布的密度函数线性组合作为目标函数，产生10000个样本，分析结果。说明混合正态分布不适合用正态函数做建议分布

给定混合多元正态分布参数`p <- 0.5
mu1 <- c(0, 0)
mu2 <- c(6, 6)
A1 <- matrix(c(1, 0.1, 0.1, 1), nrow = 2)
A2 <- matrix(c(1, -0.1, -0.1, 1), nrow = 2)`
```{r}
# mixture multivariate normal distribution p*pdf(mu1, A1) + (1-p)*pdf(mu2, A2)
p <- 0.5
mu1 <- c(0, 0)
mu2 <- c(6, 6)
A1 <- matrix(c(1, 0.1, 0.1, 1), nrow = 2)
A2 <- matrix(c(1, -0.1, -0.1, 1), nrow = 2)
A1.det <- det(A1)
A2.det <- det(A2)
A1.inv <- solve(A1)
A2.inv <- solve(A2)
f <- function(x) {
  return(as.vector(
    p * A1.det ^ (-1 / 2) * exp(-0.5 * t(x - mu1) %*% A1.inv %*% (x - mu1)) +
      (1 - p) * A2.det ^ (-1 / 2) * exp(-0.5 * t(x - mu2) %*% A2.inv %*% (x - mu2))
  ))
}
```

产生10000个样本存入`x.mixnorm`
```{r}
# generating random variates
set.seed(1234)
x.mixnorm <- mtrp(f, 10000, mu1, burn = 0)
plot(x.mixnorm$chain, pch = 20, cex = 0.5, main = "Sample Distribution",
     xlab = "1st variable", ylab = "2nd variable")
plot(density(x.mixnorm$chain[, 1]), main = "density of 1st variable")
```

观察样本分布图可以看出，这不是二维空间中双峰分布的散点图，更改`stepsize` = 3

```{r}
# generating random variates with stepsize = 3
set.seed(1234)
x.mixnorm <- mtrp(f, 10000, mu1, stepsize = 3, burn = 0)
plot(x.mixnorm$chain, pch = 20, cex = 0.5, main = "Sample Distribution",
     xlab = "1st variable", ylab = "2nd variable")
plot(density(x.mixnorm$chain[, 1]), main = "density of 1st variable")
```

观察样本分布图，这次产生的结果符合预期，对结果进行分析

```{r}
summary(x.mixnorm)
plot(x.mixnorm)
```

可以看到拒绝率为0.819，极高，说明用此种方法产生目标函数样本的效率非常低，观察时间图可以看出，大部分时间候选点都被拒绝了，Markov链转移速率非常慢。

选择小的方差，会造成样本结果的严重错误，而选择较大的方差，拒绝率又相当高，实际上，这与高维的稀疏性有关，维度越高，Markov链的拒绝率就会越高，之后要讨论的Gibbs样本分类器能很好地针对高维目标分布问题提高效率

通过上例可以看到，建议分布不是任意选取就能产生很好的效果的，需要综合给定的目标分布以及多种因素来考虑，比如，以正态分布做建议函数的随机游动Metropolis样本生成器就不适合混合多元正态分布

## 情形2 `mtrp_exp`

对目标函数的支撑集为半空间的情形（$S\subset[a_1,+\infty)\times\cdots\times[a_n,+\infty)$），编写了函数`mtrp_exp`，该函数使用指数分布做建议分布，使用独立性样本生成器来生成样本。注意建议分布与上一状态取值无关，即$f(Y|X)=f(Y)$

以下3个例子的目标函数均来自 Project 第4题

指数分布的左截尾，支撑集为$[1,+\infty)$
```{r}
# the Exp(1) distribution left-truncated at 1 (i.e., with support [1,∞))
# with pdf f(x) = exp(1 - x)
f <- function(x){
  ifelse(x >= 1, return(exp(-x)), 0)
}
```

使用函数`mtrp`产生10000个样本
```{r}
# generating random variates
set.seed(1234)
x.exp1 <- mtrp(f, 10000, 1, burn = 0)
summary(x.exp1)
plot(x.exp1)
hist(x.exp1$chain, freq = FALSE, breaks = 30,
     main = "Histogram of Samples",
     xlab = "X", xlim = c(0,4), ylim = c(0,  exp(1)))
curve(exp(1 - x), col = "red", add = TRUE)
```

使用函数`mtrp_exp`产生10000个样本
```{r}
# generating random variates using function `mtrp_exp`
set.seed(1234)
x.exp1 <- mtrp_exp(f, 10000, 1, a = 1, burn = 0)
summary(x.exp1)
plot(x.exp1)
hist(x.exp1$chain, freq = FALSE, breaks = 50,
     main = "Histogram of Samples",
     xlab = "X", xlim = c(0,4), ylim = c(0,  exp(1)))
curve(exp(1 - x), col = "red", add = TRUE)
```

观察上述结果，发现使用正态分布做建议分布的随机游动Metropolis样本生成器（`mtrp`）效率不如使用指数分布做建议分布的独立性样本生成器（`mtrp_exp`），前者拒绝率为0.3119，而后者为0。而且观察上述方法产生样本的直方图与理论（红线）对比，发现`mtrp_exp`产生的样本与理论更接近，因此，针对与指数分布相近的目标分布，使用`mtrp_exp`更为合适

## 情形3 `mtrp_unif`

对目标函数的支撑集为有限的情形（$S\subset[a_1,b_1]\times\cdots\times[a_n,b_n]$），编写了函数`mtrp_unif`，该函数使用均匀分布做建议分布，使用独立性样本生成器来生成样本。

指数分布的右截尾，支撑集为$[0,1]$
```{r}
# the Exp(1) distribution right-truncated at 1 (i.e., with support [0,1]
# with pdf f(x) = exp(1 - x) / (e - 1)
f <- function(x){
  ifelse(x >= 0 && x <=1, return(exp(-x)), 0)
}
```

使用函数`mtrp`产生10000个样本
```{r}
# generating random variates
set.seed(1234)
x.exp2 <- mtrp(f, 10000, 1, burn = 0)
summary(x.exp2)
plot(x.exp2)
hist(x.exp2$chain, freq = FALSE, main = "Histogram of Samples", xlab = "X")
curve(exp(1 - x) / (exp(1) - 1), from = 0, to = 1, col = "red", add = TRUE)
```

使用函数`mtrp_unif`产生10000个样本
```{r}
# generating random variates using function `mtrp_unif`
set.seed(1234)
x.exp2 <- mtrp_unif(f, 10000, 1, a = 0, b = 1, burn = 0)
summary(x.exp2)
plot(x.exp2)
hist(x.exp2$chain, freq = FALSE, main = "Histogram of Samples", xlab = "X")
curve(exp(1 - x) / (exp(1) - 1), from = 0, to = 1, col = "red", add = TRUE)
```

观察上述结果，发现使用正态分布做建议分布的随机游动Metropolis样本生成器（`mtrp`）效率与使用均匀分布做建议分布的独立性样本生成器（`mtrp_unif`）相近，前者拒绝率为0.1522，而后者为0.1573。但观察样本直方图与理论对比发现，`mtrp_unif`产生的样本与理论更接近（在$x=0.5$附近），因此，针对有限区间的目标分布，`mtrp_unif`是更好的选择

## 一个例子：Pareto分布

指数-Gamma混合分布，假设$\Lambda$服从$\mathrm{Gamma}(r,β)$，$X$服从$\mathrm{Exp}(\Lambda)$，也就是说，$X|(Λ = λ) ∼ f_X(x|\lambda)= λe^{−λx}$，可以通过对联合密度函数积分得到$X$的pdf为$f_X(x)=\frac{r\beta^r}{(x + \beta)^{r+1}}$

### r = 4, beta = 2

方法1：产生$(X,\Lambda)$的联合分布，抽取第一个坐标分量获得$X$的分布

```{r}
# the Exponential-Gamma mixture (Suppose that the rate parameter Λ has Gamma (
# r,β ) distribution and X has Exp(Λ) distribution. That is, X|Λ = λ ∼ f X (x|λ)
# = λe −λy .) with r = 4 and β = 2.with pdf f(x) = r * β^r / (x + β)^{r+1}
# suppose we don't know the expression of pdf f(x), however, the joint pdf
# f(x, λ) = f (x|λ) * f(λ) = λ ^ r * e^{-(x + β)*λ}is clear, so samples (x, λ) can be generated.
r <- 4
beta <- 2
f <- function(x){
  ifelse(x[1] >= 0 && x[2] >=0, x[2]^r * exp(-x[2] * (x[1]+beta)), 0)
}
```

使用函数`mtrp`产生10000个样本

```{r}
# generating random variates
set.seed(1234)
x.pareto0 <- mtrp(f, 10000, c(1, 0.5), stepsize = c(2, 1), burn = 0)
summary(x.pareto0)
plot(x.pareto0)
plot(x.pareto0$chain, pch = 20, cex = 0.5, main = "Sample Distribution",
     xlab = "X", ylab = "λ")
hist(x.pareto0$chain[, 1], freq = FALSE, main = "Histogram of Samples")
curve(r * beta^r * (x + beta)^(-(r+1)), from = 0, col = "red", add = TRUE)
```

使用函数`mtrp_exp`产生10000个样本

```{r}
# generating random variates using `mtrp_exp`
set.seed(1234)
x.pareto0 <- mtrp_exp(f, 10000, c(1, 0.5), rate = c(2, 1), burn = 0)
summary(x.pareto0)
plot(x.pareto0)
plot(x.pareto0$chain, pch = 20, cex = 0.5, main = "Sample Distribution",
     xlab = "X", ylab = "λ")
hist(x.pareto0$chain[, 1], freq = FALSE, main = "Histogram of Samples")
curve(r * beta^r * (x + beta)^(-(r+1)), from = 0, col = "red", add = TRUE)
```

可以看到，样本拒绝率分别为`mtrp`的`r 0.7198`和`mtrp_exp`的`r 0.6612`，都相当高，观察Markov转移过程发现大多数时间样本不发生转移，表现为一条长横线，但`mtrp_exp`相对要优于`mtrp`

下面考虑对X的边际分布，pdf为$f_X(x)=\frac{r\beta^r}{(x + \beta)^{r+1}}$

```{r}
# the Exponential-Gamma mixture (Suppose that the rate parameter Λ has Gamma (
# r,β ) distribution and X has Exp(Λ) distribution. That is, X|Λ = λ ∼ f_X (x|λ)
# = λe^{−λy}.) with r = 4 and β = 2. with pdf f(x) = r * β^r / (x + β)^{r+1},
# specially, it is f(x) = 64 / (x + 2)^5
r <- 4
beta <- 2
f <- function(x){
  ifelse(x >= 0, (x + beta)^(-(r+1)), 0)
}
```

使用函数`mtrp_exp`产生10000个样本

```{r}
# generating random variates using function `mtrp_exp`
set.seed(1234)
x.pareto <- mtrp_exp(f, 10000, 1, burn = 0)
summary(x.pareto)
plot(x.pareto)
hist(x.pareto$chain, freq = FALSE, main = "Histogram of Samples", xlab = "X")
curve(r * beta^r * (x + beta)^(-(r+1)), from = 0, col = "red", add = TRUE)
```

拒绝率仅为0.274，样本分布图与理论吻合地较好

### r = 1, beta = 2

改变$r$的值，$\beta$保持不变

```{r}
# If we change r from 4 to 1
r <- 1
beta <- 2
f <- function(x){
  ifelse(x >= 0, (x + beta)^(-(r+1)), 0)
}
```

使用函数`mtrp_exp`产生10000个样本

```{r}
# generating random variates using function `mtrp_exp`
set.seed(1234)
x.pareto <- mtrp_exp(f, 10000, 1, burn = 0)
summary(x.pareto)
plot(x.pareto)
hist(x.pareto$chain, freq = FALSE, main = "Histogram of Samples", xlab = "X")
curve(r * beta^r * (x + beta)^(-(r+1)), from = 0, col = "red", add = TRUE)
```

观察Markov链时间图，发现在前500次和后500次循环中均出现了长横线，而且对应的x值越大，长横线越长，这表现为在直方图中的$(5,10)$之内的异常分布，这是由于指数分布与目标函数不相近造成的，由于指数分布的pdf相比目标函数下降速度非常快，在上一状态X值很大的情形下$\alpha(X,Y)=\min\{1,\frac{f(Y)g(X)}{f(X)g(Y)}\}\approx\frac{g(X)}{g(Y)}\ll1$，即接受率非常低，因此可能会造成该点的概率异常得高。

为了补偿“指数爆炸”现象，我们考虑构造建议分布$g(\cdot|X)$，该密度函数认为$X$点左侧为均匀分布，右侧为指数分布，直观上看就是从X点水平向左砍，将砍下来的部分补在右边，如图是$g(\cdot|1)$的图像与$e^x$的对比

```{r echo=FALSE}
curve(0.5 * exp(1-x), from = 1, xlim = c(0, 3), ylim = c(0, 1), ylab = "y")
lines(c(0, 1), c(0.5, 0.5))
curve(exp(-x), col = "red", add = TRUE)
legend("topright", c("exp(x)", "g(|X)"), lty = c(1, 1), col = c("red", "black"))
```

将上述建议分布做成样本生成器`mtrp_expu`，并使用其生成10000个样本

```{r}
# generating random variates using function `mtrp_expu`
set.seed(1234)
x.pareto <- mtrp_expu(f, 10000, 1, rate = 0.5, burn = 0)
summary(x.pareto)
plot(x.pareto)
hist(x.pareto$chain, freq = FALSE, main = "Histogram of Samples", xlab = "X")
curve(r * beta^r * (x + beta)^(-(r+1)), from = 0, col = "red", add = TRUE)
```

观察上图可以看出，使用函数`mtrp_expu`生成的样本与理论分布相符合的较好，因此`mtrp_expu`可以作为情形2对于指数分布的一个有力替代者

# Gibbs样本生成器

Gibbs样本生成器实际上可以看成Metropolis-Hastings样本生成器的一种特殊情况，当目标函数为多元分布时经常使用Gibbs样本生成器。假设所有的一元条件密度是完全指定的，并且从中抽样相当简单，链条是从目标分布的边缘分布抽样生成的，且因此每一个候选点都被接受了。

令$\mathbf{X}=(X_1,\dots,X_d)$是$\mathbb{R}^d$中的随机向量，定义$d-1$维向量
$$
\mathbf{X}_{(-j)}=(X_1,\dots,X_{j-1},X_{j+1},\dots,X_d)
$$
用$f(X_j|\mathbf{X}_{(-j)})$表示给定$\mathbf{X}_{(-j)}$时$X_j$对应的一元条件分布。Gibbs样本生成器通过从每一个条件密度$f(X_j|\mathbf{X}_{(-j)})$抽样生成链条。

将Gibbs样本生成器的步骤概括如下：

1. 在时间$t=0$初始化$\mathbf{X}_0$；
2. 每次迭代（标记为$t=1,2,\dots$）重复下面过程有限（n）次：
    a. 记当前状态$\mathbf{X}_t=(X_1,X_2,\dots.X_d)$；
    b. 从坐标$\{1,2,\dots,d\}$中抽取一个数，不妨记为$j$；
    c. 从$f(X_j|\mathbf{X}_{(-j)})$生成y
    d. 令$\mathbf{X}_{t+1}=(X_1,\dots,X_{j-1},y,X_{j+1},\dots,X_d)$
    e. 增加t
    
需要证明在循环中使用的建议分布的接受率满足

$$
\alpha(X_t,Y)=\min\{1,\frac{f(Y)g(X_t|Y)}{f(X_t)g(Y|X_t)}\}=1
$$

实际上

$$
\frac{f(Y)g(X_t|Y)}{f(X_t)g(Y|X_t)}=\frac{f(Y)}{f(X_t)}\frac{1}{d}\frac{f(X_t)}{P(X_{-j})}(\frac{1}{d}\frac{f(Y)}{P(X_{-j})})^{-1}=1
$$

其中假设当前状态为$X_t$时，下一状态更新的坐标为$j$，$P(X_{-j})$表示$(X_1,\dots,X_{j-1},X_{j+1},\dots,X_d)$的联合分布。由此，证明了Gibbs样本生成器是一种特殊的Metropolis-Hastings算法，它的接受率为1，即每次都发生状态转移，因此在多维的情形效率较传统的Matropolis-Hastings样本生成器效率显著提高。

## 多元正态分布

多元正态分布是典型的Gibbs使用场合，假设$\mathbf{X}=(X_1,X_2,\dots,X_d)\sim \mathrm{N}(\mu,\Sigma)$，则$f(X_j|\mathbf{X}_{-j})=\mu_j+\Sigma_{j,-j}\Sigma_{-j,-j}(\mathbf{X}_{-j}\mu_{-j})$，其中$\Sigma_{j,-j}$为$\Sigma$第$j$行，去掉第$j$列的余子式，$\Sigma_{-j,-j}$为$\Sigma$去掉第$j$行，第$j$列的余子式。

于是，Gibbs-Normal样本生成器的步骤概括如下：

假设样本为$d$维向量，产生$n$个样本

1. 在时间$t=0$初始化$\mathbf{X}_0$；
2. 每次迭代（标记为$t=1,2,\dots$）重复下面过程有限（n）次：
    a. 记当前状态$\mathbf{X}_t=(x_1,x_2,\dots.x_d)$；
    b. 从坐标$\{1,2,\dots,d\}$中抽取一个数，不妨记为$j$；
    c. 从$X_j|\mathbf{X}_{-j}\sim \mathrm{N}(\mu_j+\Sigma_{j,-j}\Sigma_{-j,-j}^{-1}(\mathbf{X}_{-j}-\mu_{-j}),\Sigma_{j,j}-\Sigma_{j,-j}\Sigma_{-j,-j}^{-1}\Sigma_{-j,j})$生成$X_j$
    d. 令$\mathbf{X}_{t+1}=(x_1,\dots,x_{j-1},X_j,x_{j+1},\dots,x_d)$
    e. 增加t
3. 如果设置burn，舍去前burn个样本;
    返回$n\times d$的矩阵，每一行为一个样本

通过上述算法编写了函数`gibbs_norm`，可以用Gibbs样本生成器生成任意维任意参数的服从正态分布的样本

```{r}
# provide some parameters
mu <- c(1,3)
A <- matrix(c(1, 0.1, 0.1, 1), nrow = 2)
```

通过函数`gibbs_norm`产生10000个样本

```{r}
# generating random variates
set.seed(1234)
x.norm <- gbs_norm(10000, mu, A, mu, burn = 0)
summary(x.norm)
plot(x.norm)
par(mfrow = c(1, 2))
plot(x.norm$chain, pch = 20, cex = 0.5, main = "Sample Distribution",
     xlab = "1st variable", ylab = "2nd variable")
qqnorm(x.norm$chain[, 1], main = "QQ plot, 1st variable")
par(mfrow = c(1, 1))
```

可以看到二维Markov链时间图中每时刻状态的转移总与某一坐标轴平行，且一维Markov链时间图中每个分类大约有一半的时间不更新，看起来效率不高，实际上，状态每时每刻都在发生改变，该样本生成器的拒绝率为0，效率最高。与标准正态分布对比，发现在中间部分吻合地极好。

## Metropolis-Hastings样本生成器与Gibbs样本生成器的对比

```{r}
# getting `x.norm` and `x.gbs`
set.seed(123)
mu <- c(1,3)
A <- matrix(c(1, 0.1, 0.1, 1), nrow = 2)
A.inv <- solve(A)
f <- function(x) {
  stopifnot(length(x) == length(mu))
  return(as.vector(exp(-0.5 * t(x - mu) %*% A.inv %*% (x - mu))))
}
x.mtrp <- mtrp(f, 10000, mu)
x.gbs <- gbs_norm(10000, mu, A, mu)
```

```{r}
cat("Metropolis-Hastings:\n")
summary(x.mtrp)
cat("\nGibbs:\n")
summary(x.gbs)
par(mfrow = c(1, 2))
plot(x.mtrp$chain[9901:10000, 1], x.mtrp$chain[9901:10000, 2], type = "b",
     pch = 20, main = "Metropolis last 100 iters",
     xlab = "1st variable", ylab = "2nd variable")
plot(x.gbs$chain[9901:10000, 1], x.gbs$chain[9901:10000, 2], type = "b",
     pch = 20, main = "Gibbs last 100 iters",
     xlab = "1st variable", ylab = "2nd variable")
par(mfrow = c(2, 1))
plot(9501:10000, x.mtrp$chain[9501:10000, 1], type = "l", ylab = "1st variable",
     xlab = "iters", main = "Metropolis last 500 iters")
plot(9501:10000, x.gbs$chain[9501:10000, 1], type = "l", ylab = "1st variable",
     xlab = "iters", main = "Gibbs last 500 iters")
par(mfrow = c(1, 2))
plot(x.mtrp$chain, cex = 0.1, pch = 20,
     xlim = c(-2, 4), ylim = c(0, 6),
     xlab = "1st variable", ylab = "2nd variable",
     main = "Metropolis Sample Distribution")
plot(x.gbs$chain, cex = 0.1, pch = 20,
     xlim = c(-2, 4), ylim = c(0, 6),
     xlab = "1st variable", ylab = "2nd variable",
     main = "Gibbs Sample Distribution")
qqnorm(x.mtrp$chain[, 1], main = "Metropolis QQ plot, 1st variable")
qqnorm(x.gbs$chain[, 1], main = "Gibbs QQ plot, 1st variable")
par(mfrow = c(1, 1))
```

均值二者相近，且均接近理论值，但$X$和$Y$的协方差项Gibbs样本生成器表现得很好，为0.103接近理论值0.1，而Metropolis-Hastings样本生成器的结果是0.062，有很大的误差。观察二维的Markov链转移图，发现Gibbs样本生成器最终的状态比Metropolis-Hastings更稳定，不倾向于产生较多的离群值。观察$X$的Markov链转移图，发现尽管Gibbs样本生成器在$X$分量上拒绝率为0.5，但相比于Metropolis，出现长横线（较长时间内连续被拒绝）的概率要低得多。在样本分布图中可以看出Gibbs样本点的数量更多，且更加均匀。对比理论分布做出QQ图，可以看出二者均与理论分布符合的较好，但Metropolis-Hastings样本生成器产生了为数不多的离群值（左图左下角看出）。

因此，Gibbs样本生成器比Metropolis-Hastings样本生成器在产生多元正态分布上表现更好。

## 多项分布

要产生参数为$(N, \mathbf{p})$的$n$项分布，其中$N$是独立重复实验次数，$\mathbf{p}=(p_1,\dots.p_n)$是$n$维概率值向量，可以依次对每个坐标分量产生二项分布，并且有
$$
X_j|(X_1,\dots,X_{j-1})\sim \mathrm{B}(N-\sum_{k=1}^{j-1}X_k,\frac{p_j}{\sum_{k=j}^{n}p_k}))
$$
采用这种算法，产生$10000$个服从$(1000,\mathbf{p})$的样本，需要产生$10000\times1000=10^7$个二项分布数。而通过Gibbs样本生成器的方法，可以大大提高产生多项分布数的效率，若使用下面介绍的算法，假设燃烧期为$1000$，则仅需产生$10000+1000=1.1\times10^4$个二项分布数，时间前者是后者的$1000$倍

假设t时刻状态为$\mathbf{X_t}=(x_1,\dots,x_d)$，下一时刻随机选取两个坐标，不妨设为$(i,j)$，将$\mathbf{X_t}$去掉$(X_i,X_j)$的$d-2$维向量记为$\mathbf{X}_{-i,-j}=(x_1,\dots,x_{i-1},x_{i+1},\dots,x_{j-1},x_{j+1},\dots,x_d)$，则此时固定$\mathbf{X}_{-i,-j}$，将$i,j$坐标视为随机变量，考虑条件分布即$(X_i,X_j)|\mathbf{X}_{-i,-j}$，由于多项分布试验次数固定，此时满足$X_i+X_j=N-\sum_{k=1,k\ne i,j}^{d}x_k$记为$s$，即$X_i+X_j=s$，且
$$
X_i\sim\mathrm{B}(s,\frac{p_i}{p_i+p_j})
$$
，即$(X_i,X_j)|\mathbf{X}_{-i,-j}$服从一个二项分布，因此可以使用Gibbs样本生成器。

Gibbs-Multinom样本生成器的步骤：

假设样本为$d$维向量，产生$n$个样本

1. 在时间$t=0$初始化$\mathbf{X}_0$；
2. 每次迭代（标记为$t=1,2,\dots$）重复下面过程有限（n）次：
    a. 记当前状态$\mathbf{X}_t=(x_1,x_2,\dots.x_d)$；
    b. 从坐标$\{1,2,\dots,d\}$中抽取两个数，不妨记为$i,j$；
    c. 记$s=X_i+X_j$
    d. 从$X_i\sim\mathrm{B}(s,\frac{p_i}{p_i+p_j})$生成$X_i$
    e. 令$X_j=s-X_i$得到$X_j$
    f. 令$\mathbf{X}_{t+1}=(x_1,\dots,x_{i-1},X_i,x_{i+1},\dots,x_{j-1},X_j,x_{j+1},\dots,x_d)$
    g. 增加t
3. 如果设置burn，舍去前burn个样本;
    返回$n\times d$的矩阵，每一行为一个样本

通过上述算法编写了函数`gibbs_multinom`，可以用Gibbs样本生成器生成任意维任意参数的服从多项分布的样本

设置多项分布的参数(N, p) = (size, prob)

```{r}
# setting some parameters
set.seed(123)
prob <- c(0.2, 0.1, 0.1, 0.1, 0.1, 0.1,
          0.05, 0.05, 0.05, 0.05, 0.02, 0.02, 0.02, 0.02, 0.02)
p <- sample(prob)
```

使用函数`gbs_multinom`在不同$N$的情况分别产生10000个样本，观察第1个分量的Markov链转移情况以及直方图

```{r}
# generating random varaites
set.seed(1234)
par(mfrow = c(2, 1))
for (size in 10^(2:6)) {
  init <- size * p
  x.multinom <- gbs_multinom(10000, size, prob, init, burn = 0)
  plot(x.multinom$chain[1:2000, 1], type = "l", ylab = "1st variable",
       ylim=c(0.95*0.2*size, 1.05*0.2*size),
       main = paste("size =", size, "first 2000 iters"))
  plot(density(x.multinom$chain[-(1:1000), 2]), xlab = "occurs",
       xlim = c(0.08*size, 0.22*size),
       main = paste("size =", size))
  lines(density(x.multinom$chain[-(1:1000), 1]))
}
par(mfrow = c(1, 1))
```

上图是第1个分量的Markov链转移图和第1，2个分量的核密度函数估计图，坐标轴单位均与试验次数$N$成正比。可以看到，随着N的增大，Gibbs样本生成器产生的Markov链越来越稳定，样本的方差越来越小，所得结果越来越准确。特别地，当$N=100$很小时，样本的分布看不出规律，可以看出此时的Markov链是不收敛或收敛速度很慢的。

# `mcmcn`包的介绍

已经将上文中使用的用MCMC方法产生随机数的函数`mtrp`、`mtrp_exp`、`mtrp_unif`、`mtrp_expu`、`gibbs_norm`和`gbs_multinom`打包存入`mcmcn`包中，这些函数返回类别为"mcmcn"的"list"。并为"mcmcn"类分配了"summary"和"plot"方法。下面分别阐述每个函数的算法和源代码。

## 主要函数（export导出）

有`mtrp`、`mtrp_exp`、`mtrp_unif`、`mtrp_expu`、`gibbs_norm`和`gbs_multinom`共6个。

### `mtrp`

用MCMC方法产生服从任意分布的样本，采用随机游走Metropolis样本生成器，使用正态分布做建议函数。

#### 算法

Usage: mtrp(f, n, init, stepsize = 1, burn = 1000)

1. 通过传入参数获得目标分布$f(x)=$`f`，产生的样本数$n=$`n`，初始值`init`（向量），正态分布密度函数的标准差`stepsize`（向量）默认值为1，燃烧期`burn`默认值为1000
2. 检查异常情况：如密度函数无限，燃烧期为负值等等
3. 根据传入值创建局部变量样本维数$d=$`nvar <- length(init)`，迭代次数`iters <- n + burn`，样本存储矩阵`chain <- matrix(0, iters, nvar)`
4. 令 `chain[1, ] <- init`，`k <- 0`
5. 迭代`iters-1`次`for (i in 2:iters)`
    a. 从标准正态分布中抽取$n$个随机数，令候选点`y <- chain[i - 1, ] + rnorm(nvar) * stepsize`，即
        $$
        Y\sim \mathrm{N}(\text{chain[i - 1, ]},\text{diag(stepsize)})
        $$
    b. 重复循环
    
        ```{r eval=FALSE}
        while (f(y) < 1e-16) {
              y <- chain[i - 1, ] + rnorm(nvar) * stepsize
            }
        ```
        直到满足`f(y) >= 1e-16`的条件，即此时`y`位于$f(x)$支集内
    c. 判断是否更新
    
        若满足`f(y) >= runif(1) * f(chain[i - 1, ])`，即
        $$
        U\le\frac{f(Y)}{f(X_t)}
        $$
        令`chain[i, ] <- y`，即接受`y`；
        
        否则`k <- k + 1`，`chain[i, ] <- chain[i - 1, ]`，状态维持，计数器`k`自增1
6. 返回

    若`burn>=1`返回`list("chain" = chain[-(1:burn), ], "alpha" = k / iters`；
    
    否则`burn==0`，返回`list("chain" = chain, "alpha" = k / iters`.

#### 源代码

```{r eval=FALSE}
mtrp <- function(f,
                 n,
                 init,
                 stepsize = 1,
                 burn = 1000) {
  stopifnot(is.finite(f(init)))
  finit <- f(init)
  stopifnot(burn >= 0)

  # number of variates of the distribution
  nvar <- length(init)

  # number of iterations needed to operate
  iters <- n + burn

  # the variates generated in the ith iteration will be stored in chain[i, ],
  # with chain[1, ] storing the initial value
  chain <- matrix(0, iters, nvar)
  chain[1, ] <- init

  # k: counter of rejections
  k <- 0
  for (i in 2:iters) {
    y <- chain[i - 1, ] + rnorm(nvar) * stepsize

    # garantee y is in S
    while (f(y) / finit < 1e-16) {
      y <- chain[i - 1, ] + rnorm(nvar) * stepsize
    }

    # check whether to update
    if (f(y) >= runif(1) * f(chain[i - 1, ])) {
      chain[i, ] <- y
    } else {
      k <- k + 1
      chain[i, ] <- chain[i - 1, ]
    }
  }

  ifelse(burn, return(list(
    "chain" = chain[-(1:burn), ], "alpha" = k / iters
  )), return(list(
    "chain" = chain, "alpha" = k / iters
  )))
}
```

### `mtrp_exp`

用MCMC方法产生服从任意分布的样本，采用独立性样本生成器，使用指数分布做建议函数。

#### 算法

Usage: mtrp_exp(f, n, init, a = 0, rate = 1, burn = 1000)

与`mtrp`函数基本相同，除了以下几步

1. 通过传入参数获得目标分布$f(x)=$`f`，产生的样本数$n=$`n`，初始值`init`，支撑集的左边界`a`（向量），指数分布的速率`rate`默认值为1，燃烧期`burn`默认值为1000
5. 迭代`iters-1`次`for (i in 2:iters)`
    a. 从标准指数分布中抽取``nvar`个随机数，令候选点`y <- a + rexp(nvar) / rate`，即
    $$
    Y_i\sim\text{a[i]}+\mathrm{Exp}(\text{rate[i]}),i=1,\dots,d
    $$
    b. 重复循环
    c. 判断是否更新
    
    若满足`f(y) * exp(-sum(rate * (chain[i - 1, ] - a))) >=
    runif(1) * f(chain[i - 1, ]) * exp(-sum(rate * (y - a))))`，即
    $$
    U\le\frac{f(Y)g(X_t)}{f(X_t)g(Y)}
    $$
    更新，否则不更新。

#### 源代码
```{r eval=FALSE}
mtrp_exp <- function(f,
                     n,
                     init,
                     a = 0,
                     rate = 1,
                     burn = 1000) {
  stopifnot(is.finite(f(init)))
  finit <- f(init)
  stopifnot(burn >= 0)

  # number of variates of the distribution
  nvar <- length(init)

  # number of iterations needed to operate
  iters <- n + burn

  # the variates generated in the ith iteration will be stored in chain[i, ],
  # with chain[1, ] storing the initial value
  chain <- matrix(0, iters, nvar)
  chain[1, ] <- init

  # k: counter of rejections
  k <- 0
  for (i in 2:iters) {
    y <- a + rexp(nvar) / rate

    # garantee y is in S
    while (f(y) / finit < 1e-16) {
      y <- a + rexp(nvar) / rate
    }

    # check whether to update
    if (f(y) * exp(-sum(rate * (chain[i - 1, ] - a))) >= runif(1) *
        f(chain[i - 1, ]) * exp(-sum(rate * (y - a)))) {
      chain[i, ] <- y
    } else {
      k <- k + 1
      chain[i, ] <- chain[i - 1, ]
    }
  }

  ifelse(burn, return(list(
    "chain" = chain[-(1:burn), ], "alpha" = k / iters
  )), return(list(
    "chain" = chain, "alpha" = k / iters
  )))
}
```

### `mtrp_unif`

用MCMC方法产生服从任意分布的样本，采用独立性样本生成器，使用均匀分布做建议函数。

#### 算法

Usage: mtrp_unif(f, n, init, a, b, burn = 1000)

与`mtrp`函数基本相同，除了以下几步

1. 通过传入参数获得目标分布$f(x)=$`f`，产生的样本数$n=$`n`，初始值`init`，支撑集的左边界`a`（向量），支撑集的右边界`b`（向量），燃烧期`burn`默认值为1000
4. 令`sc <- b - a`为缩放倍数，用于对标准均匀分布做变换
5. 迭代`iters-1`次`for (i in 2:iters)`
    a. 从标准均匀分布中抽取`nvar`个随机数，令候选点`y <- a + sc * runif(nvar)`，即
    $$
    Y_i\sim\text{U}(\text{a[i]},\text{b[i]}),i=1,\dots,d
    $$
    b. 重复循环
    c. 判断是否更新
    
    若满足`f(y) >= runif(1) * f(chain[i - 1, ]`，即
    $$
    U\le\frac{f(Y)}{f(X_t)}
    $$
    更新，否则不更新。

#### 源代码

```{r eval=FALSE}
mtrp_unif <- function(f,
                      n,
                      init,
                      a,
                      b,
                      burn = 1000) {
  stopifnot(is.finite(f(init)))
  finit <- f(init)
  stopifnot(burn >= 0)

  # number of variates of the distribution
  nvar <- length(init)

  # number of iterations needed to operate
  iters <- n + burn

  # the variates generated in the ith iteration will be stored in chain[i, ],
  # with chain[1, ] storing the initial value
  chain <- matrix(0, iters, nvar)
  chain[1, ] <- init

  # k: counter of rejections
  k <- 0
  sc <- b - a
  for (i in 2:iters) {
    y <- a + sc * runif(nvar)

    # garantee y is in S
    while (f(y) / finit < 1e-16) {
      y <- a + sc * runif(nvar)
    }

    # check whether to update
    if (f(y) >= runif(1) * f(chain[i - 1, ])) {
      chain[i, ] <- y
    } else {
      k <- k + 1
      chain[i, ] <- chain[i - 1, ]
    }
  }

  ifelse(burn, return(list(
    "chain" = chain[-(1:burn), ], "alpha" = k / iters
  )), return(list(
    "chain" = chain, "alpha" = k / iters
  )))
}

```

### `mtrp_expu`

用MCMC方法产生服从任意分布的样本，采用Metropolis-Hastings样本生成器，使用指数和均匀的混合分布做建议函数。

#### 算法

mtrp_expu(f, n, init, a = 0, rate = 1, burn = 1000)

与`mtrp_exp`函数基本相同，除了以下几步

5. 迭代`iters-1`次`for (i in 2:iters)`
    a. 从`rexpu`分布中抽取随机数，令候选点`y[j] <- rexpu(1, a[j], x[j], rate[j])`（`rexpu`为`mcmcn`包中所含），即
    $$
    Y_i\sim\text{Expu}(\text{a[i]},\text{x[i]},\text{rate[i]}),i=1,\dots,d
    $$
    其中$\text{Expu}(a,x,\lambda)$的pdf为
    $$
    \begin{cases}
    \frac{1}{x-a+\lambda^{-1}},\quad a\le y\le x\\[6pt]
    \frac{1}{x-a+\lambda^{-1}}e^{-\lambda(y-x)},\quad y>x
    \end{cases}
    $$
    b. 重复循环
    c. 判断是否更新
    
    若满足`f(y) * g(x, y) >= runif(1) * f(x) * g(y, x)`，即
    $$
    U\le\frac{f(Y)g(X_t|Y)}{f(X_t)g(Y|X_t)}
    $$
    更新，否则不更新。

#### 源代码

```{r eval=FALSE}
mtrp_expu <- function(f,
                      n,
                      init,
                      a = 0,
                      rate = 1,
                      burn = 1000) {
  stopifnot(is.finite(f(init)))
  finit <- f(init)
  stopifnot(burn >= 0)

  # number of variates of the distribution
  nvar <- length(init)

  # check a and rate
  stopifnot(length(a) == 1 || length(a) == nvar)
  if (length(a) == 1)
    a <- rep(a, nvar)
  stopifnot(length(rate) == 1 || length(rate) == nvar)
  if (length(rate) == 1)
    rate <- rep(rate, nvar)

  # number of iterations needed to operate
  iters <- n + burn

  # the variates generated in the ith iteration will be stored in chain[i, ],
  # with chain[1, ] storing the initial value
  chain <- matrix(0, iters, nvar)
  chain[1, ] <- init

  # k: counter of rejections
  k <- 0

  # generating chain[i, ]
  for (i in 2:iters) {
    x <- chain[i - 1, ]
    y <- numeric(nvar)
    for (j in 1:nvar) {
      y[j] <- rexpu(1, a[j], x[j], rate[j])
    }

    # garantee y is in S
    while (f(y) / finit < 1e-16) {
      for (j in 1:nvar) {
        y[j] <- rexpu(1, a[j], x[j], rate[j])
      }
    }

    # proposal distribution g(y|x)
    g <- function(y, x) {
      return(prod(ifelse(
        y <= x, 1 / (x - a + 1 / rate), exp(-rate * (y - x)) / (x - a + 1 / rate)
      )))
    }

    # check whether to update
    if (f(y) * g(x, y) >= runif(1) * f(x) * g(y, x)) {
      chain[i, ] <- y
    } else {
      k <- k + 1
      chain[i, ] <- x
    }
  }

  ifelse(burn, return(list(
    "chain" = chain[-(1:burn),], "alpha" = k / iters
  )), return(list(
    "chain" = chain, "alpha" = k / iters
  )))
}

```

### `gbs_norm`

用MCMC方法产生服从多元正态分布的样本，采用Gibbs样本生成器。

#### 算法

Usage: gbs_norm(n, mu, A, init, burn = 1000)

1. 通过传入参数获得生的样本数$n=$`n`，正态分布参数`mu`（向量），`A`（矩阵），初始值`init`（向量），燃烧期`burn`默认值为1000
2. 检查异常情况：如`mu`与`A`不相容，燃烧期为负值等等
3. 根据传入值创建局部变量样本维数$d=$`nvar <- length(init)`，迭代次数`iters <- n + burn`，样本存储矩阵`chain <- matrix(0, iters, nvar)`，`A`的每个对角元余子式的逆`A.inv`是一个$(d-1)\times (d-1)\times d$维的数组`A.inv[, , i] <- solve(A[-i, -i])`，即
    $$
    \text{A.inv[, , i]}=\text{A[-i, -i]}^{-1}
    $$
4. 令 `chain[1, ] <- init`，`k <- 0`
5. 迭代`iters-1`次`for (i in 2:iters)`
    a. 在$1,\dots,d$中抽取一个坐标分量`sample(1:nvar, 1)`
    b. 令`chain[i, -j] <- chain[i - 1, -j]`，即$X^{(t+1)}_{-j}=X^{(t)}_{-j}$
    c. 令
        ```{r eval=FALSE}
        chain[i, j] <- rnorm(1, mu[j] + A[j, -j] %*% A.inv[, , j] %*% (chain[i, -j] - mu[-j]),
        (A[j, j] - A[j, -j] %*% A.inv[, , j] %*% A[-j, j]) ^ (1 / 2))
        ```
        即
        $$
        X_j|\mathbf{X}_{-j}\sim \mathrm{N}(\mu_j+\Sigma_{j,-j}\Sigma_{-j,-j}^{-1}(\mathbf{X}_{-j}-\mu_{-j}),\Sigma_{j,j}-\Sigma_{j,-j}\Sigma_{-j,-j}^{-1}\Sigma_{-j,j})
        $$
6. 返回

    若`burn>=1`返回`chain[-(1:burn), ]`；否则`burn==0`，返回`chain`.

#### 源代码

```{r eval=FALSE}
gbs_norm <- function(n,
                     mu,
                     A,
                     init,
                     burn = 1000) {
  stopifnot(length(mu) == nrow(A) && nrow(A) == ncol(A))
  stopifnot(burn >= 0)

  # number of variates of the distribution
  nvar <- length(mu)

  # Calculate the inverse of A[-i, -i] for i in 1:nvar and store the results in A.inv
  # A.inv will be used for calculating the conditional distribution
  A.inv <- array(0, dim = c(nvar - 1, nvar - 1, nvar))
  for (i in 1:nvar) {
    A.inv[, , i] <- solve(A[-i, -i])
  }

  # number of iterations needed to operate
  iters <- n + burn

  # the variates generated in the ith iteration will be stored in chain[i, ],
  # with chain[1, ] storing the initial value
  chain <- matrix(0, iters, nvar)
  chain[1, ] <- init
  for (i in 2:iters) {
    j <- sample(1:nvar, 1)
    chain[i, -j] <- chain[i - 1, -j]
    chain[i, j] <- rnorm(1,
                         mu[j] + A[j, -j] %*% A.inv[, , j] %*% (chain[i, -j] - mu[-j]),
                         (A[j, j] - A[j, -j] %*% A.inv[, , j] %*% A[-j, j]) ^ (1 / 2))
  }

  ifelse(burn, return(chain[-(1:burn), ]), return(chain))
}
```

### `gbs_multinom`

用MCMC方法产生服从多元正态分布的样本，采用Gibbs样本生成器。

#### 算法

Usage: gbs_multinom(n, size, prob, init, burn = 1000)

1. 通过传入参数获得生的样本数$n=$`n`，多项分布参数`size`，`prob`（向量），初始值`init`（向量），燃烧期`burn`默认值为1000
2. 检查异常情况：如`prob`和不为1，`prob`与`init`长度不同，`init`之和与`size`不相同，燃烧期为负值等等
3. 根据传入值创建局部变量样本维数$d=$`nvar <- length(init)`，迭代次数`iters <- n + burn`，样本存储矩阵`chain <- matrix(0, iters, nvar)`
4. 令 `chain[1, ] <- init`，`k <- 0`
5. 迭代`iters-1`次`for (i in 2:iters)`
    a. 在$1,\dots,d$中抽取两个个坐标分量存入`x`，`x <- sample(1:nvar, 2)`，不妨设为$i,j$
    b. 令`s <- sum(chain[i - 1, c(x[1], x[2])])`，即$s=x_i+x_j$
    c. 令`chain[i, -c(x[1], x[2])] <- chain[i - 1, -c(x[1], x[2])]`，即$X^{(t+1)}_{-i,-j}=X^{(t)}_{-i,-j}$
    d. 令`chain[i, x[1]] <- rbinom(1, s, prob[x[1]] / (prob[x[1]] + prob[x[2]]))`，
    `chain[i, x[2]] <- s - chain[i, x[1]]`，即
        $$
        X_i\sim\mathrm{B}(s,\frac{p_i}{p_i+p_j})
        $$
        和
        $$
        X_j=s-X_i
        $$
6. 返回

    若`burn>=1`返回`chain[-(1:burn), ]`；否则`burn==0`，返回`chain`.

#### 源代码

```{r eval=FALSE}
gbs_multinom <- function(n,
                      size,
                      prob,
                      init,
                      burn = 1000) {
  stopifnot(sum(prob) == 1)
  stopifnot(length(prob) == length(init))
  stopifnot(sum(init) == size)
  stopifnot(burn >= 0)

  # number of variates of the distribution
  nvar <- length(prob)

  # number of iterations needed to operate
  iters <- n + burn

  # the variates generated in the ith iteration will be stored in chain[i, ],
  # with chain[1, ] storing the initial value
  chain <- matrix(0, iters, nvar)
  chain[1, ] <- init
  for (i in 2:iters) {
    x <- sample(1:nvar, 2)
    s <- sum(chain[i - 1, c(x[1], x[2])])
    chain[i, -c(x[1], x[2])] <- chain[i - 1, -c(x[1], x[2])]
    chain[i, x[1]] <- rbinom(1, s, prob[x[1]] / (prob[x[1]] + prob[x[2]]))
    chain[i, x[2]] <- s - chain[i, x[1]]
  }

  ifelse(burn, return(chain[-(1:burn), ]), return(chain))
}
```

## 辅助函数

有`rexpu`、`summary.mcmcn`和`plot.mcmcn`共3个。

### `rexpu`

用于产生均匀分布和指数分布的混合分布，`rexpu(n, a = 0, b = 1, rate = 1)`的pdf和标准指数分布pdf对比如下

```{r echo=FALSE}
# suppose X ~ exponential-uniform mixture with parameters(a = 0, b = 1, rate = 1)
# the plot below shows the different pdfs of X and Exp(1)
curve(0.5 * exp(1-x), from = 1, xlim = c(0, 3), ylim = c(0, 1), ylab = "y")
lines(c(0, 1), c(0.5, 0.5))
curve(exp(-x), col = "red", add = TRUE)
legend("topright", c("Exp(1)", "X"), lty = c(1, 1), col = c("red", "black"))
```

#### 源代码

```{r eval=FALSE}
rexpu <- function(n, a = 0, b = 0, rate = 1) {
  x.unif <- runif(n, a, b)
  x.exp <- b + rexp(n, rate)
  p <- rbinom(n, 1, 1 / (rate * (b - a) + 1))
  x <- ifelse(p, x.exp, x.unif)
  return(x)
}
```

### `summary.mcmcn`

用于展示返回的"mcmcn"类（样本）信息，包括拒绝率、单变量均值分位数、多变量协方差矩阵等。

#### 源代码

```{r eval=FALSE}
summary.mcmcn <- function(x) {
  nvar = ncol(x$chain)
  if(!identical(x$alpha, NULL)) cat("Rejection rate:", x$alpha, "\n\n")
  print(summary(x$chain))
  cat("\nCovarience Matrix:\n")
  print(var(x$chain))
  return(invisible())
}
```

### `plot.mcmcn`

用于展示"mcmcn"类（样本）的Markov链，会绘制第一个变量和前两个变量（若维数>=2）的Markov链。


#### 源代码

```{r eval=FALSE}
plot.mcmcn <- function(x) {
  n = nrow(x$chain)
  nvar = ncol(x$chain)
  if(nvar >= 2) {
    par(mfrow = c(1, 2))
    plot(x$chain[1:100, 1], x$chain[1:100, 2], type = "b", pch = 20,
         main = "first 100 iters", xlab = "1st variable", ylab = "2nd variable")
    plot(x$chain[(n-99):n, 1], x$chain[(n-99):n, 2], type = "b",
         pch = 20, main = "last 100 iters", xlab = "1st variable", ylab = "2nd variable")
  }
  par(mfrow = c(2, 1))
  plot(1:500, x$chain[1:500, 1], type = "l",
       xlab = "iters", ylab = "1st variable",
       main = "first 500 iters")
  plot((n-499):n, x$chain[(n-499):n, 1], type = "l",
       xlab = "iters", ylab = "1st variable",
       main = "last 500 iters")
  par(mfrow = c(1, 1))
  return(invisible())
}
```


# 总结

- 马尔可夫链蒙特卡罗（MCMC）方法，是以Markov链为概率模型的蒙特卡罗积分方法，Metropolis-Hastings算法是最基本的MCMC法，给定概率分布，通过选取的建议分布构造Markov链，在满足正则条件的情况下，Markov链运行一段长时间后收敛，其平稳分布就是要抽样的目标分布。
- 由于效率问题，Markov链不能无限运行下去，因此要选定一个燃烧期，假设运行到燃烧期后Markov链即达到平稳分布，燃烧期的选取可以通过监测Markov链是否收敛来完成。
- Metropolis样本生成器，随机游动Metropolis样本生成器，独立性样本生成器是Metropolis-Hastings算法实现的一些方法，根据给定概率分布的特性（如对称性，均匀性，支集的范围等）选取适当的样本生成器和建议函数，可以提高效率。不适合的建议分布甚至会得到错误的结果（尽管理论上可行）。
- 初值的选取也非常重要，好的初值可以使Markov链很快收敛，坏的初值甚至会导致Markov链有限长时间内不会收敛。
- 对于随机游动Metropolis样本生成器，最常用的建议分布是正态函数，它的拒绝率和收敛性对步长的选取十分敏感，可以通过实验来选取最佳步长。
- Gibbs样本生成器是Metropolis-Hastings算法的一个特殊情形，它通过使用1维（或2维）的条件分布每次更新一个坐标分量（假定条件分布已知且容易产生随机数），以1的接受率更新状态，因此效率要远高于传统的Metropolis-Hastings样本生成器，在高维的情况优势更加显著。

在这次实验中，通过理论证明正确性，构造产生Markov链的算法，并编写了对应的函数，尝试选取了不同的分类器和不同的建议函数，选取了多个例子，对常见或不常见的分布进行模拟实验，并与理论对比，得到结论或改进方案，并优化设计的算法和编写的函数，最后学习了R包的创建，将编写的函数和用到的例子装入R包`mcmcn`，方便调用和维护。

# 项目组成员及任务分工和组织

成员：黄佳谊、张月程

**任务分工和组织：**

实验报告：

| 任务                   | 分工   |
| ---------------------- | ------ |
| MCMC理论阐述           | 黄佳谊 |
| MCMC的R语言实现        | 黄佳谊 |
| 利用MCMC进行贝叶斯推断 | 张月程 |

课堂展示：

| 任务          | 分工   |
| ------------- | ------ |
| PPT制作及展示 | 黄佳谊 |

R包`mcmcn`编写

| 任务            | 分工   |
| --------------- | ------ |
| R代码及对象文档 | 黄佳谊 |
| 使用指南        | 张月程 |

# 参考文献

[1] 统计计算:使用R/(美) 玛利亚 L. 里佐著 胡锐, 李义译, 北京:机械工业出版社,2019

[2] 随机过程/(美) Sheldon M. Ross著 龚光鲁译, 北京:机械工业出版社,2013

[3] 统计学习方法/李航著, 第2版, 北京:清华大学出版社,2019

[4] R包开发/(美) Hadley Wickham著 杨学辉译, 北京:人民邮电出版社,2016

[5] 高级R语言编程指南/(美) 哈德利·威克汉姆著 李洪成等译, 北京:机械工业出版社,2016
